# Docker

## Теория

Более развернутую теорию по Docker см. [здесь](https://gitlab/anetto/bos/blob/master/docker.md).

Что такое Докер? Это такой способ изоляции ваших приложений друг от друга с помощью linux namespaces. Он легок в управлении, расширении, миграции и подходит для огромного спектра задач начиная от разработки приложений и сборки пакетов и заканчивая тестами-пятиминутками (запустить-проверить 1-2 команды-закрыть и забыть, да так чтобы еще и мусор за тобой прибрали). 
Стоит только представлять себе на первом этапе, что контейнер состоит из слоев, т.е. из слепков состояний файловой системы. Подробнее позже.

**Про виртуалки**

Важно помнить, что Docker — средство изоляции процесса(задачи), а это  значит относиться к докеру как к виртуалке нельзя. Но он имеет многие похожие фишки, как и у виртуализации:

1. независимость — контейнер может быть перемещен на любую ОС с  docker-службой на борту и контейнер будет работать. (Официально — да, по  факту, нет уверенности, что совместимость такая радужная, как пони, радуга и  бабочки.)
2. самодостаточность — контейнер будет выполнять свои функции в любом месте, где бы его не запустили.

И тем не менее он отличается от привычной виртуализации:

1. Внутри контейнера находится минимально необходимый набор софта,  необходимый для работы вашего процесса. Это уже не полноценная ОС,  которую надо мониторить, следить за остатком места итд итп.
2. Используется другой подход к виртуализации. Имеется ввиду сам принцип — там нет привычной хостовой ОС.
3. Следует особо относиться к контейнеру и генерируемым им данным.  Контейнер это инструмент обработки данных, но не инструмент их хранения.  Как пример — контейнер — это гвоздезабивающая машина, подаваемые на  вход данные — доска и гвоздь, результат работы — забить гвоздь в доску.  При этом доска с гвоздем не остается частью той самой гвоздезабивающей  машины, результат отдельно, инструмент отдельно. Выходные данные не  должны сохраняться внутри контейнера (можно, но это не docker-way).  Поэтому, контейнер это либо worker (отработал, отчитался в очередь),  либо, если это, например, веб-сервер, то нужно использовать внешние  тома. (все это очень просто, не стоит в этом моменте грустить). 

**О процессах**

Теперь, когда мы выяснили что такое docker, разберемся что там внутри. Нужно запомнить следующие постулаты:

1. Контейнер живет, пока живет процесс, вокруг которого рождается контейнер.
2. Внутри контейнера этот процесс имеет pid=1
3. Рядом с процессом с pid=1 можно порождать сколько угодно других  процессов (в пределах возможностей ОС, естественно), но убив  (рестартовав) именно процесс с pid=1, контейнер выходит. 
4. Внутри контейнера вы увидите привычное согласно стандартам FHS (Filesystem Hierarchy Standard) расположение директорий. Расположение это идентично исходному дистрибутиву (с которого взят контейнер).
5. Данные, создаваемые внутри контейнера остаются в контейнере и нигде  более не сохраняются (ну, еще к этому слою есть доступ из хостовой ОС).  удалив контейнер — потеряете все ваши изменения. Поэтому данные в  контейнерах не хранят, а выносят наружу, на хостовую ОС.

**Про контейнеры и образы**

Докер образ (image) — это некоторый набор слоёв. Каждый слой — результат работы команды в Dockerfile. Грубо говоря образ — это шаблон на основе которого вы будете запускать контейнеры. Все что запускается на основе этого образа есть контейнер, или инстанс. т.е. с одного образа можно 
запустить несколько одинаковых копий этого образа — контейнеров. Причем потом, после каких-то манипуляций, из этого контейнера можно создать шаблон — новый образ. Хранится все это безобразие в /var/lib/docker. 

Список образов в вашей системе можно глянуть командой:

```
docker images
```

Список контейнеров:

```
docker ps
```

ключ -a покажет в том числе остановленные, а ключ -s — его размер. т.е. сколько фактически, сейчас, в рантайме, этот контейнер занимает места на диске.

**А как называть эти вс контейнеры и образы?**

У образа существует 3 поля, имеющих отношения к именованию:
1) Репозиторий
2) Тег
3) Image ID
Репозиторий — реальный или нереальный, это то место, откуда или куда ваш образ будет скачан\загружен, или это просто выдуманное имя, если загружать никуда вы его не собираетесь.
Тег — обычно это версия продукта. По идее — это любой набор символов. (из разрешенного списка [a-z0-9.-] итп.) Если тега нет, то автоматически используется слово **latest**. Тег ставится через символ : от имени репозитория и подставляется автоматически если его не указать при push\pull.
ImageID — локально генерируемый уникальный ID вашего образа, по которому этим образом можно оперировать.

Таким образом вы или автор контейнера влияете на репозиторий и\или тег, а система локально — на ID. Но, кстати вам никто не мешает переиспользовать любое чужое имя репозитория, другой вопрос что запушить (push, загрузить) в него вы не сможете

Например:
1/2/3-blah.blah.blah — имя вашего локального образа, вы его выдумали
projects/my_first_docker — тоже имя вашего локального образа
projects/my_first_docker:latest — то же самое имя, но с тегом. эквивалентно предыдущему.
projects/my_first_docker:1.13.33 — а вот это уже конкретная версия образа в этом репозитории.
projects/my_first_docker:1.13.34
projects/my_first_docker:1.13.35
… итд — все это один и тот же проект, но версии ваших образов будут разными.

Одна из больших фишек докера — переиспользование слоев. Это значит, что если слой не менялся, то новая версия вашего образа сможет использовать слои других контейнеров. Например корневой слой с ubuntu будет использоваться всеми контейнерами, основанными на ubuntu. Если ваш второй слой, например, установка nginx, а третий — положить конфиг, то при изменении конфига и сборке нового образа, он будет состоять из 2-х старых слоев и одним новым. Но, не спешите радоваться. Хоть это переиспользование коллосально может экономить место, докер так еще может  подпортить жизнь этими слоями, которые он создает на каждый чих. Слои эти за счет переиспользования будут иметь адовые зависимости друг от друга и в конечном итоге на крупных инсталляциях, где собирается множество контейнеров это будет та самая слоеная вакханалия, о которой упоминалось выше. Но не стоит воспринимать сказанное как то, что с вами обязательно случится, в данном случае речь идет о нагруженной системе с десятками новых билдов в день. Такой вакханалии на обычных серверах нет — там у вас всего будет парочка контейнеров. И с другой стороны, чистится это тоже довольно просто — просто rm -rf. Самое важное для вас — контейнеры, которые можно заупскать заново. Ну а результат работы вы и так в контейнере не храните.

Еще примеры:
debian:stretch — образ debian, версия образа — stretch (не число, но слово)
centos:7 — аналогично debian.
mongo:3.2 — образ mongodb версии 3.2, скачанный с публичного репозитория
nginx — latest stable nginx.

Причем чаще всего на хабе можно увидеть разнообразные версии нужного вам софта. Так например mongo даст вам скачать и 3.2 и 3.4 и 3.6 и даже дев версию и разные промежуточные.

Представьте, как удобно — у вас крутится монга 3.2, вы хотите попробовать рядом другую версию. просто качаете контейнер с новой версией и запускаете. и не надо поднимать никаких виртуалок, настраивать их, чистить за собой. Все что нужно чтобы удалить докер образ — 
ввести команду docker rmi . А весит он во много раз меньше.  

Следует помнить: один и тот же образ может иметь сколько угодно имен репозитория и тегов, но будет иметь одинаковый imageid. При этом, образ не будет удален, пока все теги этого образа не будут удалены. т.е. скачав образ ubuntu, задав ему новый тег вы получите в списке 2 образа с
разными именами, но одинаковыми imageid. и удалив ubuntu:stretch, вы просто удалите один из тегов, а сам образ останется жить.


 Чтобы задать другое имя для существующего образа используется команда:

```bash
docker tag <existing image name> <new image name>
```

Для удаления образа:

```bash
docker rmi <image>
```

А вот контейнеры имеют 2 поля имеют отношение к именованию:
1) CONTAINER ID
2) Name

**CONTAINER ID** — тут то же самое — это уникальное имя конкретного уникального запущенного инстанса образа. Проще говоря — уникальное имя запущенного образа. Образ может быть запущен сколько угодно раз и каждая копия получит уникальное имя.
**Name** — а вот это уже имя, более удобное и читабельное. 
Дело в том, что запуская различные образа вы никогда точно не узнаете с каким именем вы его запустили, пока не полезете не посмотрите запущенные контейнеры, или не возьмете этот выхлоп при запуске контейнера. С учетом того что вы можете логировать на stdout, то ваше имя контейнера 
потеряется. Так вот можно заранее задавать имя для запущенного контейнера с помощью ключа --name, тогда и оперировать им можно с сразу известным именем.

Список контейнеров:

```
docker ps
```


 Для удаления контейнера:

```
docker rm <container>
```

**Свой контейнер**

Для создания своих контейнеров существует механизм сборки — docker  build. Он использует набор инструкций в Dockerfile для сборки вашего  собственного образа. При сборке контейнера внутри используется оболочка  sh и ваши команды исполняются в ней.

1. Каждая законченная команда — создает слой файловой системы с  результатами изменений, порожденными этой командой. т.е. например  выполнив команду apt install htop, вы создадите слой, который будет  содержать результат выполения этой команды — бинарники, библиотеки итд. в  конечном итоге каждый такой слой будет наложен друг на друга, а затем  на исходный (образ операционной системы) и вы получите конечный  результат. Отсюда проистекают несколько ограничений:
2. Слои независимы друг от друга. это значит что запущенная в процессе  сборки какая-нибудь служба внутри контейнера существует только в  пределах своего слоя. Яркий пример — попытка залить базу в mysql. Как  это обычно происходит? нужно запустить mysql-сервер и следующей командой  залить базу. Здесь это так не сработает. Создастся слой, который  сохранит результаты запуска mysql (логи, итп) и потом mysql просто  завершится. в следующем слою (при выполнении команды заливки базы)  мускуль уже не будет запущен и будет ошибка. Решение этой проблемы —  всего-навсего объединять команды через &&.
3. А вот постоянные данные будут накладываться от первой команды до  последней друг на друга и храниться постоянно от слоя к слою. Поэтому,  создав какой-либо файл первой командой, вы сможете к нему обратиться и в  последней команде.

**Это не докер-вэй**

Докер довольно таки мусорит слоями при билде. Кроме того вы можете  оставлять кучу остановленных контейнеров. Удалить все это одной командой

```
docker system prune
```

Докер по задумке виртуализирует именно один процесс (с любым кол-вом потомков). Никто вам не мешает конечно запихнуть в один контейнер и 10 процессов, но тогда пеняйте на себя.
Сделать это можно с помощью, например, supervisor.

Но, скажете вы, как же быть со службами, которые ну всю свою жизнь будут вместе и не должны разделяться? использовать контент, который будут генерировать друг для дргуга?

Для того чтобы сделать это красиво и правильно есть docker-compose — это yaml файл, который описывает N ваших контейнеров и их взаимоотношения. Какой контейнер с каким скрестить, какие порты друг для друга открыть, какими данными поделиться.

В случае с compose вам, на самом деле, и управлять своим проектом проще. например, связка nginx+uwsgi+mongo — это 3 контейнера, хотя точно известно, что никто кроме nginx не будет ходить в uwsgi, а кроме uwsgi — никто в mongo. да и жить они будут всегда вместе. (ЭТО ЧАСТНЫЙ СЛУЧАЙ).
Вот тут у нас получается следующая ситуация — ваше приложение (api) будет обновляться часто — вы его пишете и пушите каждый день. а, например, релизы nginx или mongodb выходят куда реже — может месяц, может дольше. Так зачем каждый раз билдить этого тяжеловеса, когда изменения то всего происходят в одном месте? Когда придет время обновить nginx, вы просто смените имя тега и всесто ребилда проекта, просто скачается новый контейнер с nginx.

## Практика

На этом этапе можно попробовать потрогать контейнеры и поучить необходимые команды. 

* Посмотрим, какие образы есть в системе

  ```
  docker images
  ```

* Образов может быть очень много, найдем только образы ubuntu

  ```
  docker images ubuntu
  ```

* Запустим bash-процесс внутри образа ubuntu. И обратим внимание на его PID - он равен единице

  ```
  docker run -ti ubuntu bash
  ```

* Откроем еще один терминал и командой 

  ```
  docker ps
  ```

  увидим наш запущенный контейнер

* Закроем его (Ctrl+D) и снова выполним верхнюю команду. 

* Чтобы посмотреть все контейнеры:

  ```
  sudo docker ps -a
  ```

  Можно увидеть конетейне в состоянии exited.

* Запустим наш контейнер в фоновом режиме по его айдишнику

  ```
  docker start f3fd87cd2b8a
  ```

* Теперь присоединимся к уже запущенному контейнеру и запустим еще одну оболочку bash

  ```
  docker exec -ti f3fd87cd2b8a bash
  ```

* выполняем ps aux — обратите внимание, тот, первый bash, с pid 1 живет, а мы в контейнере теперь управляем им через bash с pid=7. И теперь, если мы выйдем, контейнер будет жить.

* Резюме:

  **run** — взять образ X и создать контейнер Z с процессом Y
  **exec** — взять контейнер Z и запустить в нем процесс N, при этом процесс Y будет работать как и прежде.

## Свой докер-образ.

Учимся использовать dockerfile.
Здесь — два подхода к разработке:

1. взять готовый и подточить под себя
2. сделать самому с нуля

Вариант первый — когда вы уверены что за вас прекрасно сделали уже всю работу. Например, зачем устанавливать nginx, когда можно взять готовый официальный контейнер с nginx. Особенно это касается тех систем, которые не ставятся в одну команду или которые например в debian имеют 
устаревшие версии, а на докер хабе их билдят более свежие стабильные. 
Тем более там уже сделана автосборка — свежие версии там прилетают довольно быстро.

Вариант второй — вам не нравится подход автора образа (например, официального не нашлось, а есть только на хабе васи пупкина). Никто не мешает посмотреть как сделал это василий, а потом пойти и сделать самому. Ну или в случае если вы просто пишете свою логику, которой точно нигде нет. 

В файлах Dockerfile содержатся инструкции по созданию образа. С них,  набранных заглавными буквами, начинаются строки этого файла. После  инструкций идут их аргументы. Инструкции, при сборке образа,  обрабатываются сверху вниз. Вот как это выглядит:

```dockerfile
FROM ubuntu:18.04
COPY . /app
```

**Приведём список инструкций Dockerfile с краткими комментариями.**

1. `FROM` — задаёт базовый (родительский) образ.
2. `LABEL` — описывает метаданные. Например — сведения о том, кто создал и поддерживает образ.
3. `ENV` — устанавливает постоянные переменные среды.
4. `RUN` — выполняет команду и создаёт слой образа. Используется для установки в контейнер пакетов.
5. `COPY` — копирует в контейнер файлы и папки.
6. `ADD` — копирует файлы и папки в контейнер, может распаковывать локальные .tar-файлы.
7. `CMD` — описывает команду с аргументами, которую нужно  выполнить когда контейнер будет запущен. Аргументы могут быть  переопределены при запуске контейнера. В файле может присутствовать лишь  одна инструкция `CMD`.
8. `WORKDIR` — задаёт рабочую директорию для следующей инструкции.
9. `ARG` — задаёт переменные для передачи Docker во время сборки образа.
10. `ENTRYPOINT` — предоставляет команду с аргументами для вызова во время выполнения контейнера. Аргументы не переопределяются.
11. `EXPOSE` — указывает на необходимость открыть порт.
12. `VOLUME` — создаёт точку монтирования для работы с постоянным хранилищем.

Теперь рассмотрим еще один Dockerfile, который собирает маленький образ. В нём имеются механизмы, определяющие команды, вызываемые во время выполнения контейнера.

```dockerfile
FROM python:3.7.2-alpine3.8
LABEL maintainer="jeffmshale@gmail.com"
ENV ADMIN="jeff"
RUN apk update && apk upgrade && apk add bash
COPY . ./app
ADD https://raw.githubusercontent.com/discdiver/pachy-vid/master/sample_vids/vid1.mp4 \
/my_app_directory
RUN ["mkdir", "/a_directory"]
CMD ["python", "./my_script.py"]
```

Возможно, на первый взгляд этот файл может показаться довольно сложным. Поэтому давайте с ним разберёмся. Базой этого образа является официальный образ Python с тегом 3.7.2-alpine3.8. Проанализировав этот код можно увидеть, что данный базовый образ включает в себя Linux, 
Python, и, по большому счёту, этим его состав и ограничивается. Образы ОС Alpine весьма популярны в мире Docker. Дело в том, что они отличаются маленькими размерами, высокой скоростью работы и безопасностью. Однако образы Alpine не отличаются широкими возможностями, характерными для обычных операционных систем. Поэтому для того, чтобы собрать на основе такого образа что-то полезное, создателю образа нужно установить в него 
необходимые ему пакеты.

**Cвязь ФС контейнера с хостом**

Теперь давайте рассмотрим способ доступности данных с хостовой ос из  контейнера. Причин этого может быть несколько: передача файлов,  конфигурации, или просто сохранение обработанных данных на диск. Как я  уже упоминал ранее данные не пропадают просто так если выключить  контейнер, но они и остаются в этом контейнере. вытащить потом их — это  ненужная и глупая задача. Докер-вэй — монтирование хостового  каталога\файла внутрь контейнера. А если проще — мапинг папки\файла  снаружи на папку\файл внутри. поскольку это монтирование, то изменение с  одной стороны всегда будет видно и с другой. Таким образом, внося  изменение в конфиг с хостовой ос — вы можете заставить сервис внутри  контейнера работать по-другому. И наоборот — для сохранения базы данных  на хосте в одном, строго определенном, удобном для вас месте. Или логов.

```
-v /source/folder:/destination/folder -v /path/to/file:/path/to/config
```

**Запускатор ваших сервисов**

Когда вы уже набилдили себе парочку контейнеров, возникает вопрос, как же их автоматически запускать, не прикладывая к этому усилий? Используем systemd.

Например, создайте файл:

```bash
sudo nano /etc/systemd/system/my-project.service
```

и занесите туда строки:

```
[Unit]
Description=my first docker service
Requires=docker.service
After=docker.service

[Service]
Restart=always
RestartSec=3
ExecStartPre=/bin/sh -c "/usr/bin/docker rm -f my-project 2> /dev/null || /bin/true"
ExecStart=/usr/bin/docker run --rm -a STDIN -a STDOUT -a STDERR -p 80:80 -v /etc/my-project/:/etc/my-project --name my-project:2.2








ExecStop=/usr/bin/docker stop my-project

[Install]
WantedBy=multi-user.target
```

На что здесь следует обратить внимание:

**ExecStartPre** — команда которая выполняется при запуске\перезапуске и убивает если вдруг существует какой-то завалившийся контейнер с именем my-project. Ну мало ли откуда он взялся (глюк, кривые руки) — с этой строчкой мы в любом случае прибьем то, что мешает стартануть и в любом случае завершим команду положительно.

**--rm** — ключ позволяет удалить контейнер после его остановки. мусора не останется после остановки службы

**--name my-project** — имя вашего контейнера

**-a STDIN -a STDOUT -a STDERR — attach to std** — присоеиниться к потокам ввода\вывода\ошибок вашего процесса. В бекграунде это значит что все что не пишется в лог попадет в журнал systemd

**-p** — мапинг 0.0.0.0:80 хоста -> 80 порт внутри контейнера

**-v** — мапинг папки с конфигами
Ключей можно указывать несколько, например несколько разных портов. В том числе можно еще указать и протокол — tcp или udp. По-умолчанию — tcp.

Сохранить файл и запустить службу:

```bash
systemctl start my-project.service
```

Теперь управляем вашей службой как обычным systemd демоном, а journalctl — смотрим stdout вашего демона.

**Построим инфраструктуру**

У нас будут следующие синтетические примеры:
send.py -> rabbitmq -> read.py

Т.е. будет 3 контейнера, первый будет ставить задачи в очередь, последний считывать. Все это будет управляться через systemd.

sender.py будет ставить каждые 5 секунд в очередь рандомное число от 1 до 7, а воркер (receiver.py) будет считывать это число и имитировать работу — методом простоя кол-ва секунд равное полученному числу.

Мы будем пытаться сделать наши микросервисы так, как это делают правильные пацаны — внутри контейнера код сервиса, а конфиги и логи — снаружи. Это позволит нам поменять адреса очереди, логин, пароль итд без нового билда контейнера. Просто поправить файлик и перезапустить 
контейнер, вот и все дела. Таким образом нам понядобится директория в /etc и в /var/log, куда мы будем мапить логи и конфиги, соответственно. Вообще такой подход удобен. Зайдя на любой сервер с докером, где могут сосуществовать рядом один или несколько микросервисов, вы всегда знате 
где искать конфиги или логи. 

**RabbitMQ**

RabbitMQ — диспетчер обмена сообщениями между приложениями. в нашем случае будет использована примитивная очередь. в эту очередь будет помещаться задание и приниматься воркером. Конфиги настройки очереди мы захардкодим внутрь контейнера. Всего в папке rabbitmq у нас будет 3 файла — Dockerfile и 2 файла с конфигами. Их содержимое — в спойлерах под листингом. Настройка очереди, пользователя, прав доступа — в json файле definitions.

```bash
## Создадим папки для каждой службы
mkdir -p ~/Documents/my_project/{sender,receiver,rabbitmq}
```

```bash
cd ~/Documents/my_project/rabbitmq
```

Создайте и заполните необходимые файлы.  Особое внимание нужно обратить на файл Dockerfile, где описывается построение образа. И файл my_project-rabbitmq.service где описывается запуск сервиса. 


<details> 
  <summary>/etc/systemd/system/my_project-rabbitmq.service</summary>
<pre>
[Unit] 
Description=my first docker service
Requires=docker.service
After=docker.service</br>
[Service]
Restart=always
RestartSec=3
ExecStartPre=/bin/sh -c "/usr/bin/docker rm -f rabbitmq 2> /dev/null || /bin/true"
ExecStart=/usr/bin/docker run --rm -a STDIN -a STDOUT -a STDERR -p 5672:5672 --name rabbitmq rabbitmq:1.0
ExecStop=/usr/bin/docker stop rabbitmq
    </br>
[Install]
WantedBy=multi-user.target
</pre>
    </details>

<details> 
  <summary>~/Documents/my_project/rabbitmq/rabbitmq.conf</summary>
<pre>
management.load_definitions = /etc/rabbitmq/definitions.json
</pre>
    </details>

<details> 
  <summary>~/Documents/my_project/rabbitmq/definitions.json</summary>
<pre>
{"rabbit_version":"3.7.2","users":[{"name":"username","password_hash":"P2bFyWm2oSwuzoRDw37nRYgagL0ciZSGus3kYnkG1aNaUWeD","hashing_algorithm":"rabbit_password_hashing_sha256","tags":""},{"name":"guest","password_hash":"SjeLNFEWLHwuC5QRAaZIF/SX/uMasQFyt5+dELgKK03TgsC8","hashing_algorithm":"rabbit_password_hashing_sha256","tags":"administrator"}],"vhosts":[{"name":"virtualhost"},{"name":"/"}],"permissions":[{"user":"guest","vhost":"/","configure":".*","write":".*","read":".*"},{"user":"username","vhost":"virtualhost","configure":".*","write":".*","read":".*"}],"topic_permissions":[],"parameters":[],"global_parameters":[],"policies":[],"queues":[],"exchanges":[],"bindings":[]}
</pre>
    </details>

<details> 
  <summary>~/Documents/my_project/rabbitmq/Dockerfile</summary>
<pre>
## Если у вас на виртуалке нет образа rabbitmq:management, то найти его можно в \\\\fs\Кафедры\\732\\БОС rabbitmw.tar
## и установить его командой docker load -i rabbitmq.tar
FROM rabbitmq:management
</br>
ADD rabbitmq.conf /etc/rabbitmq/rabbitmq.conf
ADD definitions.json /etc/rabbitmq/
</br>
RUN chown rabbitmq:rabbitmq /etc/rabbitmq/rabbitmq.conf /etc/rabbitmq/definitions.json
</br>
CMD ["rabbitmq-server"]
</pre>
    </details>

После этого построим докер образ на основе созданного Dockerfile, запустим службу и проверем работоспособность

```bash
## построим докер образ на основе созданного Dockerfile
docker build -t rabbitmq:1.0 .
## запускаем службу
systemctl start my_project-rabbitmq
## проверяем
docker ps
systemctl status my_project-rabbitmq
```

**Отправляльщик сообщений**

```bash
cd ~/Documents/my_project/sender
```

Создайте и заполните необходимые файлы.  Особое внимание нужно обратить на файл Dockerfile, где описывается построение образа. И файл my_project-rabbitmq.service где описывается запуск сервиса. 


<details> 
  <summary>/etc/systemd/system/my_project-sender.service</summary>
<pre>
[Unit]
Description=my first docker service
Requires=docker.service
After=docker.service
<br>
[Service]
Restart=always
RestartSec=3
ExecStartPre=/bin/sh -c "/usr/bin/docker rm -f sender 2> /dev/null || /bin/true"
ExecStart=/usr/bin/docker run --network="host" --rm -a STDIN -a STDOUT -a STDERR -v /home/user/Documents/my_project/sender:/etc/my_project/sender --name sender sender:1.0
ExecStop=/usr/bin/docker stop sender
<br>
[Install]
WantedBy=multi-user.target
</pre>
    </details>

<details> 
  <summary>~/Documents/my_project/sender/sender.py</summary>
<pre>
# -*- coding: utf-8 -*-
import pika, base64, time, random
<br>
pika_username = "username"
pika_password = base64.b64decode("MTIzNDU2Nzg5MA==")
pika_addr = "127.0.0.1"
pika_port = 5672
pika_virtualhost ="virtualhost"
pika_queue = "queue"
<br>
def send_message_rabbitmq(message="Hello World!"):
    credentials = pika.PlainCredentials(pika_username, pika_password)
    parameters = pika.ConnectionParameters(pika_addr, pika_port, pika_virtualhost, credentials)
    connection = pika.BlockingConnection(parameters)
    channel = connection.channel()
    channel.queue_declare(queue=pika_queue, durable=True)
    channel.basic_publish(exchange='',
                          routing_key=pika_queue,
                          body=message,
                          properties=pika.BasicProperties(
                             delivery_mode=2,
                          ))
    connection.close()
<br>
while True:
  send_message_rabbitmq(str(random.randint(1,7)))
  time.sleep(5)
</pre>
    </details>

<details> 
  <summary>~/Documents/my_project/sender/Dockerfile</summary>
<pre>
FROM ubuntu:latest 
<br>
RUN apt-get update || echo && apt-get -y -q install python3-pika
<br>
COPY sender.py /opt/
<br>
CMD ["usr/bin/python3", "/opt/sender.py"]
</pre>
    </details>

Если есть ошибки при построении контейнера, связанные с невозможностью установки pika, при построении образа в файл /etc/apt/sources.list запишите следующие строки

```bash
deb [arch=amd64] http://ru.archive.ubuntu.com/ubuntu/ bionic main restricted universe multiverse
deb [arch=amd64] http://ru.archive.ubuntu.com/ubuntu/ bionic-updates main restricted universe multiverse
deb [arch=amd64] http://security.ubuntu.com/ubuntu/ bionic-security main restricted universe multiverse

```

После этого построим докер образ на основе созданного Dockerfile, запустим службу и проверем работоспособность

```bash
## построим докер образ на основе созданного Dockerfile
docker build -t sender:1.0 .

## запускаем службу
systemctl start my_project-sender
## проверяем
docker ps
systemctl status my_project-sender
```

**Receiver — или наш работяга-worker.**

```bash
cd ~/Documents/my_project/receiver
```

Создайте и заполните необходимые файлы.  Особое внимание нужно обратить на файл Dockerfile, где описывается построение образа. И файл my_project-rabbitmq.service где описывается запуск сервиса. 


<details> 
  <summary>/etc/systemd/system/my_project-receiver.service</summary>
<pre>
[Unit]
Description=my first docker service
Requires=docker.service
After=docker.service
<br>
[Service]
Restart=always
RestartSec=3
ExecStartPre=/bin/sh -c "/usr/bin/docker rm -f receiver 2> /dev/null || /bin/true"
ExecStart=/usr/bin/docker run --rm --network="host" -a STDIN -a STDOUT -a STDERR -v /home/user/Documents/my_project/receiver:/etc/my_project/receiver --name receiver receiver:1.0
ExecStop=/usr/bin/docker stop receiver
<br>
[Install]
WantedBy=multi-user.target
</pre>
    </details>

<details> 
  <summary>~/Documents/my_project/receiver/Dockerfile</summary>
<pre>
FROM ubuntu:latest
<br>
RUN apt-get update || echo && apt-get -y -q install python3-pika
<br>
RUN mkdir /var/log/receiver
<br>
COPY receiver.py /opt/
<br>
CMD ["/usr/bin/python3","-u", "/opt/receiver.py"]
</pre>
    </details>

<details>   <summary>~/Documents/my_project/receiver/receiver.py</summary>
    <pre>
# -*- coding: utf-8 -*-
import pika, base64, time
<br>
log_file = open("/var/log/receiver/receiver.log","a")
<br>
pika_username ="username"
pika_password = base64.b64decode("MTIzNDU2Nzg5MA==")
pika_addr = "127.0.0.1"
pika_port = 5672
pika_virtualhost ="virtualhost"
pika_queue = "queue"
<br>
credentials = pika.PlainCredentials(pika_username, pika_password)
parameters  = pika.ConnectionParameters(pika_addr, pika_port, pika_virtualhost, credentials)
connection  = pika.BlockingConnection(parameters)
channel     = connection.channel()
<br>
channel.queue_declare(queue=pika_queue, durable=True)
<br>
print(' [*] Waiting for messages. To exit press CTRL+C')
<br>
def callback(ch, method, properties, body):
    print(" [x] Received %r" % (body,)) #this goes to stdout
    print("[x] Received %r" % (body,), file=log_file) #this goes to log file
    time.sleep(int(body.decode('ascii')))
    channel.basic_ack(delivery_tag = method.delivery_tag)
<br>
channel.basic_qos(prefetch_count=1)
channel.basic_consume(callback, queue=pika_queue)
<br>
channel.start_consuming()
</pre>   
</details>

После этого построим докер образ на основе созданного Dockerfile, запустим службу и проверем работоспособность

```bash
## построим докер образ на основе созданного Dockerfile
docker build -t receiver:1.0 .
## запускаем службу
systemctl start my_project-receiver
## проверяем
docker ps
systemctl status my_project-receiver
```

Посмотреть результаты работы развернутого примера можно в логах докера командой:

```bash
docker logs <id контейнера>
```

или в journalctl, куда был перенаправлен stdout.